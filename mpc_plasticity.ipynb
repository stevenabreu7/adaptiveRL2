{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpc_utils import load_train_test_data_27s, load_train_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 1350, 7), (200, 1350, 1), (25, 1350, 7), (25, 1350, 1), (200, 1350, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = load_train_test_data_27s(include_L=True)\n",
    "l_train, l_test = x_train[:, :, 7:], x_test[:, :, 7:]\n",
    "x_train, x_test = x_train[:, :, :7], x_test[:, :, :7]\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape, l_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lmu_torch import LMUModel\n",
    "import torch\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, input_size, hidden_size, memory_size, theta, epochs=100, batch_size=16, lr=1e-3, device='cpu'):\n",
    "    model = LMUModel(input_size=input_size, hidden_size=hidden_size, memory_size=memory_size, output_size=1, theta=theta, device=device)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss = torch.nn.MSELoss()\n",
    "    n_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "    for epoch in range(epochs+1):\n",
    "        # eval\n",
    "        if epoch % 50 == 0:\n",
    "            loss_train = []\n",
    "            for batch_idx in range(n_batches-1):\n",
    "                model.eval()\n",
    "                x = x_train[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "                y = y_train[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "                x = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "                y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "                ypr = model(x)\n",
    "                loss_train.append(loss(ypr, y).item())\n",
    "            loss_test = []\n",
    "            for batch_idx in range(max(1, x_test.shape[0] // batch_size)):\n",
    "                model.eval()\n",
    "                x = x_test[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "                y = y_test[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "                x = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "                y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "                ypr = model(x)\n",
    "                loss_test.append(loss(ypr, y).item())\n",
    "            print(epoch, 'train', np.array(loss_train).mean(), 'test', np.array(loss_test).mean())\n",
    "\n",
    "        # train\n",
    "        epoch_loss = []\n",
    "        model.train()\n",
    "        for batch_idx in range(n_batches-1):\n",
    "            x = x_train[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "            y = y_train[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "            x = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "            y = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss.append(l.item())\n",
    "\n",
    "        # log training loss\n",
    "        avg_epoch_loss = np.array(epoch_loss).mean()\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch, avg_epoch_loss)\n",
    "        else:\n",
    "            print(epoch, avg_epoch_loss, end='\\r')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train 0.1053507687015967 test 0.09588231891393661\n",
      "0 0.09099637581543489\n",
      "10 0.02335170233114199\n",
      "20 0.012840221043337475\n",
      "30 0.009863007136366585\n",
      "40 0.009216473099182953\n",
      "50 train 0.009070090695538303 test 0.01331960316747427\n",
      "50 0.009083957496014509\n",
      "60 0.009032332169061357\n",
      "70 0.008989603766663508\n",
      "80 0.008944488257508387\n",
      "90 0.008893085643649101\n",
      "100 train 0.008791436483575539 test 0.01313480269163847\n",
      "100 0.008832149588587608\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 64\n",
    "memory_size = 32\n",
    "theta = 16\n",
    "\n",
    "length_model = train_model(x_train, l_train, x_test, l_test, 7, hidden_size, memory_size, theta, epochs=100, batch_size=16, lr=1e-3)\n",
    "model_name = f'mpc_models/lmu_length_7-1-{hidden_size}-{memory_size}-{theta}.pt'\n",
    "torch.save(length_model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train 0.49338705973191693 test 0.4251982569694519\n",
      "0 0.3003939932042902\n",
      "10 0.030197971246459267\n",
      "20 0.017432937398552895\n",
      "30 0.013452758758582851\n",
      "40 0.011286370117555965\n",
      "50 train 0.009826862337914381 test 0.011015781201422215\n",
      "50 0.009889701804654165\n",
      "60 0.008871115955778143\n",
      "70 0.008098993958397345\n",
      "80 0.0075436259450560265\n",
      "90 0.007089623715728521\n",
      "100 train 0.006654849614609371 test 0.007684497162699699\n",
      "100 0.006732017733156681\n",
      "110 0.0064287441359324885\n",
      "120 0.006165519145063378\n",
      "130 0.0059427381916479635\n",
      "140 0.0057501419108699665\n",
      "150 train 0.005503616719083352 test 0.006301489192992449\n",
      "150 0.005579321433536031\n",
      "160 0.0054474276998503644\n",
      "170 0.0052666694179854615\n",
      "180 0.0050775121304799214\n",
      "190 0.0049805663187395445\n",
      "200 train 0.0049021320459856224 test 0.005426288582384586\n",
      "200 0.004923061510040002\n",
      "210 0.0047615041786974125\n",
      "220 0.0046357327479530475\n",
      "230 0.004675860918888991\n",
      "240 0.004516785710372708\n",
      "250 train 0.004872065418484536 test 0.005519535858184099\n",
      "250 0.004748562583699822\n"
     ]
    }
   ],
   "source": [
    "xtrl = np.concatenate([x_train, l_train], axis=2)\n",
    "xtel = np.concatenate([x_test, l_test], axis=2)\n",
    "action_model_true_length = train_model(xtrl, y_train, xtel, y_test, 8, hidden_size, memory_size, theta, epochs=250, batch_size=16, lr=1e-3)\n",
    "model_name = f'mpc_models/lmu_action_true_7-1-{hidden_size}-{memory_size}-{theta}_250epochs.pt'\n",
    "torch.save(action_model_true_length.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 64\n",
    "memory_size = 32\n",
    "theta = 16\n",
    "\n",
    "lmodel = LMUModel(input_size=7, output_size=1, hidden_size=hidden_size,\n",
    "                  memory_size=memory_size, theta=theta)\n",
    "lmodel.load_state_dict(torch.load('mpc_models/lmu_length_7-1-64-32-16.pt'))\n",
    "\n",
    "amodel = LMUModel(input_size=8, output_size=1, hidden_size=hidden_size,\n",
    "                  memory_size=memory_size, theta=theta)\n",
    "amodel.load_state_dict(torch.load('mpc_models/lmu_action_true_7-1-64-32-16_250epochs.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.backpropamine_torch import BackpropamineRNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "# model = LMUModel(input_size=7, output_size=1, hidden_size=hidden_size, \n",
    "#                     memory_size=memory_size, theta=theta)\n",
    "model = BackpropamineRNN(isize=7, hsize=128, osize=1, freeze_plasticity=False)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "n_batches = x_train.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:45<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.19694998792626642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:46<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.07346870817921379\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:46<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.042940097099000755\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:46<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.03048459542068568\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:47<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.026092683219096878\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:45<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.02199589325623079\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:45<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0.01878795569593256\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:45<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.01678415404802019\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:46<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.015266723761504347\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:45<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0.013889077119529247\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:45<00:00,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.012865105051208626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs+1):\n",
    "\n",
    "    hidden_hebb = model.initialZeroStateHebb(batch_size)\n",
    "\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for batch_idx in tqdm(range(n_batches-1)):\n",
    "        hidden_hebb = model.initialZeroStateHebb(batch_size)\n",
    "        x = x_train[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "        y = y_train[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "        \n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = []\n",
    "        for t in range(x.shape[1]):\n",
    "            yp, hidden_hebb = model(x[:,t,:], hidden_hebb)\n",
    "            y_pred.append(yp)\n",
    "        y_pred = torch.stack(y_pred, dim=1)\n",
    "\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss.append(l.item())\n",
    "\n",
    "    avg_epoch_loss = np.array(epoch_loss).mean()\n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch, avg_epoch_loss)\n",
    "    else:\n",
    "        print(epoch, avg_epoch_loss, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from models.lmu_torch import leCunUniform\n",
    "from scipy.signal import cont2discrete\n",
    "\n",
    "\n",
    "class LMUCell(nn.Module):\n",
    "    \"\"\" \n",
    "    LMU Cell\n",
    "\n",
    "    Parameters:\n",
    "        input_size (int) : \n",
    "            Size of the input vector (x_t)\n",
    "        hidden_size (int) : \n",
    "            Size of the hidden vector (h_t)\n",
    "        memory_size (int) :\n",
    "            Size of the memory vector (m_t)\n",
    "        theta (int) :\n",
    "            The number of timesteps in the sliding window that is represented using the LTI system\n",
    "        learn_a (boolean) :\n",
    "            Whether to learn the matrix A (default = False)\n",
    "        learn_b (boolean) :\n",
    "            Whether to learn the matrix B (default = False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, memory_size, theta, learn_a = False, learn_b = False):\n",
    "        \n",
    "        super(LMUCell, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.memory_size = memory_size\n",
    "        self.f = nn.Tanh()\n",
    "\n",
    "        A, B = self.stateSpaceMatrices(memory_size, theta)\n",
    "        A = torch.from_numpy(A).float()\n",
    "        B = torch.from_numpy(B).float()\n",
    "\n",
    "        if learn_a:\n",
    "            self.A = nn.Parameter(A)\n",
    "        else:\n",
    "            self.register_buffer(\"A\", A)\n",
    "    \n",
    "        if learn_b:\n",
    "            self.B = nn.Parameter(B)\n",
    "        else:\n",
    "            self.register_buffer(\"B\", B)\n",
    "\n",
    "        # Declare Model parameters:\n",
    "        ## Encoding vectors\n",
    "        self.e_x = nn.Parameter(torch.empty(1, input_size))\n",
    "        self.e_h = nn.Parameter(torch.empty(1, hidden_size))\n",
    "        self.e_m = nn.Parameter(torch.empty(1, memory_size))\n",
    "        ## Kernels\n",
    "        self.W_x = nn.Parameter(torch.empty(hidden_size, input_size))\n",
    "        self.W_h = nn.Parameter(torch.empty(hidden_size, hidden_size))\n",
    "        self.W_m = nn.Parameter(torch.empty(hidden_size, memory_size))\n",
    "\n",
    "        self.initParameters()\n",
    "\n",
    "    def initParameters(self):\n",
    "        \"\"\" Initialize the cell's parameters \"\"\"\n",
    "\n",
    "        # Initialize encoders\n",
    "        leCunUniform(self.e_x)\n",
    "        leCunUniform(self.e_h)\n",
    "        nn.init.constant_(self.e_m, 0)\n",
    "        # Initialize kernels\n",
    "        nn.init.xavier_normal_(self.W_x)\n",
    "        nn.init.xavier_normal_(self.W_h)\n",
    "        nn.init.xavier_normal_(self.W_m)\n",
    "\n",
    "    def stateSpaceMatrices(self, memory_size, theta):\n",
    "        \"\"\" Returns the discretized state space matrices A and B \"\"\"\n",
    "\n",
    "        Q = np.arange(memory_size, dtype = np.float64).reshape(-1, 1)\n",
    "        R = (2*Q + 1) / theta\n",
    "        i, j = np.meshgrid(Q, Q, indexing = \"ij\")\n",
    "\n",
    "        # Continuous\n",
    "        A = R * np.where(i < j, -1, (-1.0)**(i - j + 1))\n",
    "        B = R * ((-1.0)**Q)\n",
    "        C = np.ones((1, memory_size))\n",
    "        D = np.zeros((1,))\n",
    "\n",
    "        # Convert to discrete\n",
    "        A, B, C, D, dt = cont2discrete(\n",
    "            system = (A, B, C, D), \n",
    "            dt = 1.0, \n",
    "            method = \"zoh\"\n",
    "        )\n",
    "        \n",
    "        return A, B\n",
    "\n",
    "    def forward(self, x, state):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            x (torch.tensor): \n",
    "                Input of size [batch_size, input_size]\n",
    "            state (tuple): \n",
    "                h (torch.tensor) : [batch_size, hidden_size]\n",
    "                m (torch.tensor) : [batch_size, memory_size]\n",
    "        \"\"\"\n",
    "\n",
    "        h, m = state\n",
    "\n",
    "        # Equation (7) of the paper\n",
    "        u = F.linear(x, self.e_x) + F.linear(h, self.e_h) + F.linear(m, self.e_m) # [batch_size, 1]\n",
    "\n",
    "        # Equation (4) of the paper\n",
    "        m = F.linear(m, self.A) + F.linear(u, self.B) # [batch_size, memory_size]\n",
    "\n",
    "        # Equation (6) of the paper\n",
    "        h = self.f(\n",
    "            F.linear(x, self.W_x) +\n",
    "            F.linear(h, self.W_h) + \n",
    "            F.linear(m, self.W_m)\n",
    "        ) # [batch_size, hidden_size]\n",
    "\n",
    "        return h, m\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class LMUModel(torch.nn.Module):\n",
    "    \"\"\" A simple model for the psMNIST dataset consisting of a single LMU layer and a single dense classifier \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, memory_size, theta, learn_a = False, learn_b = False):\n",
    "        super(LMUModel, self).__init__()\n",
    "        self.lmu = LMUCell(input_size, hidden_size, memory_size, theta, learn_a, learn_b)\n",
    "        self.classifier = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        h_0 = torch.zeros(x.shape[0], self.lmu.hidden_size)\n",
    "        m_0 = torch.zeros(x.shape[0], self.lmu.memory_size)\n",
    "        state = (h_0, m_0)\n",
    "        for t in range(x.shape[1]):\n",
    "            state = self.lmu(x[:,t,:], state) # [batch_size, hidden_size]\n",
    "            output = self.classifier(state[0])\n",
    "            out.append(output) # [batch_size, output_size]\n",
    "        return torch.stack(out, dim=1) # [batch_size, seq_len, output_size]\n",
    "\n",
    "class LinearHebbian(nn.Module):\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int) -> None:\n",
    "        factory_kwargs = {'device': None, 'dtype': None}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        self.bias = nn.Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # as in torch.nn.Linear\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "        # initialize the hebbian weights\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpclmu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
